{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"import random\nimport os\nimport itertools\nfrom tqdm import tqdm\n\nrandom.seed(0)\n\npartition_dir = \"/kaggle/input/customer2shopdataset/Customer2Shop/Customer2Shop/Eval/list_eval_partition.txt\"\npartition = open(partition_dir, \"r\")\nlst = []\nwith open(partition_dir, 'r') as f:\n    for i,line in enumerate(f):\n        if i < 2:\n            continue\n        lst.append(line.split())\n\nrandom.shuffle(lst)\n\nstatistic = {'train': 0, 'val': 0, 'test': 0}\ndata = {'train': [], 'val': [], 'test': []}\nmax_statistic = {'train': 8000, 'val': 1000, 'test': 1000}\ntrain, valid, test = [], [], []\nfor sample in tqdm(lst):\n    if statistic == max_statistic:\n        break\n    sample[0] = \"/kaggle/input/customer2shopdataset/Customer2Shop/Customer2Shop/\" + sample[0]\n    sample[1] = \"/kaggle/input/customer2shopdataset/Customer2Shop/Customer2Shop/\" + sample[1]\n    if not (os.path.exists(sample[0]) and os.path.exists(sample[1])):\n        continue\n    type_sample = sample[3]\n    sample[2] = 1\n    if statistic[type_sample] < max_statistic[type_sample]:\n        statistic[type_sample] += 1\n        data[type_sample].append(sample)\n        \nimg_dir = \"/kaggle/input/customer2shopdataset/Customer2Shop/Customer2Shop/img\"\nclothesDir = [img_dir + \"/\" + i for i in os.listdir(img_dir)]\ntypeDir = list(itertools.chain.from_iterable([[dir + \"/\" + i for i in os.listdir(dir)] for dir in clothesDir]))\nidDir = list(itertools.chain.from_iterable([[dir + \"/\" + i for i in os.listdir(dir)] for dir in typeDir]))\n\nstatistic = {'train': 0, 'val': 0, 'test': 0}\nrandom.shuffle(idDir)\nidDir = idDir[:1000]\npair = []\nfor i in range(len(idDir)):\n    for j in range(i+1, len(idDir)):\n        pair.append((i, j))\nrandom.shuffle(pair)\npair = pair[:12000]\nstatus = \"train\"\nfor i, sample in tqdm(enumerate(pair)):\n    id1 = idDir[sample[0]]\n    id2 = idDir[sample[1]]\n    comsumer = sorted(os.listdir(id1))[0]\n    shop = sorted(os.listdir(id2))[-1]\n    if \"comsumer\" in comsumer and \"shop\" in shop:\n        comsumer_dir = id1+\"/\"+comsumer\n        shop_dir = id2+\"/\"+shop\n    else:\n        continue\n    data[status].append([comsumer_dir, shop_dir, 0, status])\n    statistic[status] += 1\n    if statistic[status] >= max_statistic[status]:\n        if status == 'train':\n            status = 'val'\n        elif status == 'val':\n            status = 'test'\n        else:\n            break\n\nrandom.shuffle(data['train'])\nrandom.shuffle(data['val'])\nrandom.shuffle(data['test'])\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:17:26.676544Z","iopub.execute_input":"2023-07-08T13:17:26.676887Z","iopub.status.idle":"2023-07-08T13:17:26.693241Z","shell.execute_reply.started":"2023-07-08T13:17:26.676853Z","shell.execute_reply":"2023-07-08T13:17:26.692229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"import os\nos.mkdir(\"/kaggle/working/owndataset/\")\nwith open(r'/kaggle/working/owndataset/train.txt', 'w') as fp:\n    for item in data['train']:\n        fp.write(\"%s\\n\" % item)\n    print('Done')\nwith open(r'/kaggle/working/owndataset/val.txt', 'w') as fp:\n    for item in data['val']:\n        fp.write(\"%s\\n\" % item)\n    print('Done')\nwith open(r'/kaggle/working/owndataset/test.txt', 'w') as fp:\n    for item in data['test']:\n        fp.write(\"%s\\n\" % item)\n    print('Done')\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:17:26.694703Z","iopub.execute_input":"2023-07-08T13:17:26.695032Z","iopub.status.idle":"2023-07-08T13:17:26.707472Z","shell.execute_reply.started":"2023-07-08T13:17:26.695003Z","shell.execute_reply":"2023-07-08T13:17:26.706514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from ast import literal_eval\nread_data = {}\nreads = []\nwith open(r'/kaggle/working/owndataset/train.txt', 'r') as fp:\n    for line in fp:\n        reads.append(line)\n    print(\"Done\")\nread_data['train'] = [literal_eval(line[:-1]) for line in reads]\nreads = []\nwith open(r'/kaggle/working/owndataset/val.txt', 'r') as fp:\n    for line in fp:\n        reads.append(line)\n    print(\"Done\")\nread_data['val'] = [literal_eval(line[:-1]) for line in reads]\nreads = []\nwith open(r'/kaggle/working/owndataset/test.txt', 'r') as fp:\n    for line in fp:\n        reads.append(line)\n    print(\"Done\")\nread_data['test'] = [literal_eval(line[:-1]) for line in reads]\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:17:26.708634Z","iopub.execute_input":"2023-07-08T13:17:26.709484Z","iopub.status.idle":"2023-07-08T13:17:26.722957Z","shell.execute_reply.started":"2023-07-08T13:17:26.709452Z","shell.execute_reply":"2023-07-08T13:17:26.722066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read_data['train'][:5]","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:17:26.727576Z","iopub.execute_input":"2023-07-08T13:17:26.727862Z","iopub.status.idle":"2023-07-08T13:17:26.732384Z","shell.execute_reply.started":"2023-07-08T13:17:26.727839Z","shell.execute_reply":"2023-07-08T13:17:26.731530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\nfrom tqdm import tqdm\nimport pandas as pd\nimport os\nread_data = {}\ndata = pd.read_csv(\"/kaggle/input/add-csv/pairs_for_training.csv\")\ndata = shuffle(data)\nprefix = \"/kaggle/input/imageretrievaldataset/\"\na = [data.loc[i].tolist()[1:5] for i in tqdm(range(len(data)))]\nb = []\nk = 0\ni = 0\npbar = tqdm(total=len(data)+1)\nwhile i < len(data):\n    if os.path.exists(prefix+a[i][0]) and os.path.exists(prefix+a[i][1]):\n        b.append([prefix+a[i][0], prefix+a[i][1], a[i][3], a[i][2]])\n        k+=1\n        pbar.update(1)\n    i += 1\npbar.close()\nprint(\"Available: \", k)\nread_data['train'] = b","metadata":{"execution":{"iopub.status.busy":"2023-07-11T10:26:04.605020Z","iopub.execute_input":"2023-07-11T10:26:04.606024Z","iopub.status.idle":"2023-07-11T10:36:12.925324Z","shell.execute_reply.started":"2023-07-11T10:26:04.605986Z","shell.execute_reply":"2023-07-11T10:36:12.924383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/imageretrievaldataset/pairs_for_testing.csv\")\ndata = shuffle(data)\nprefix = \"/kaggle/input/imageretrievaldataset/\"\na = [data.loc[i].tolist()[1:6] for i in tqdm(range(len(data)))]\nb = []\nk = 0\ni = 0\npbar = tqdm(total=len(data)+1)\nwhile i < len(data):\n    if os.path.exists(prefix+a[i][0]) and os.path.exists(prefix+a[i][1]):\n        b.append([prefix+a[i][0], prefix+a[i][1], a[i][4], a[i][3]])\n        k+=1\n        pbar.update(1)\n    i += 1\npbar.close()\nprint(\"Available: \", k)\nread_data['test'] = b","metadata":{"execution":{"iopub.status.busy":"2023-07-11T10:36:12.927550Z","iopub.execute_input":"2023-07-11T10:36:12.928263Z","iopub.status.idle":"2023-07-11T10:43:40.294978Z","shell.execute_reply.started":"2023-07-11T10:36:12.928227Z","shell.execute_reply":"2023-07-11T10:43:40.293937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = []\nfor i in read_data['train']:\n    if type(i[2]) not in a:\n        a.append(type(i[2]))\n        print(i[2])\n\nprint(a)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T10:43:40.296267Z","iopub.execute_input":"2023-07-11T10:43:40.296617Z","iopub.status.idle":"2023-07-11T10:43:40.365910Z","shell.execute_reply.started":"2023-07-11T10:43:40.296584Z","shell.execute_reply":"2023-07-11T10:43:40.364904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass huydataset(Dataset):\n    def __init__(self, file):\n        firsts = []\n        seconds = []\n        labels = []\n        for line in file:\n            path1, path2, label, _ = line\n            firsts.append(path1)\n            seconds.append(path2)\n            labels.append(float(label))\n        self.data = {\"firsts\":firsts, \"seconds\":seconds, \"labels\":labels}\n        self.preprocess = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n    \n    def __len__(self):\n        return len(self.data[\"labels\"])\n    \n    def __getitem__(self, idx):\n        def merge_width(image1, image2):\n            new_image = Image.new(\"RGB\", (image1.size[0], image1.size[1]+image2.size[1]), (250, 250, 250))\n            new_image.paste(image1,(0,0))\n            new_image.paste(image2,(0,image1.size[1]))\n            return new_image\n        \n        def merge_height(image1, image2):\n            new_image = Image.new(\"RGB\", (256, 256), (250, 250, 250))\n            new_image.paste(image1,(0,0))\n            new_image.paste(image2,(128,0))\n            return new_image\n        \n        img1 = Image.open(self.data[\"firsts\"][idx])\n        img1 = transforms.Resize((256, 128))(img1)\n        img2 = Image.open(self.data[\"seconds\"][idx])\n        img2 = transforms.Resize((256, 128))(img2)\n        merged_imgs = self.preprocess(merge_height(img1, img2)).unsqueeze(0)\n        return {\"labels\":self.data[\"labels\"][idx], \"merged_imgs\":merged_imgs}\n        \n    def collate_fn(self, batch):\n        def get_data(batch):\n            data = {i:[] for i in batch[0]}\n            for i in batch:\n                for k in i:\n                    data[k].append(i[k])\n            return data\n        \n        batch = get_data(batch)\n        batch[\"merged_imgs\"] = torch.cat(batch[\"merged_imgs\"], dim=0)\n        batch[\"labels\"] = torch.tensor(batch[\"labels\"])\n        return batch","metadata":{"execution":{"iopub.status.busy":"2023-07-11T10:52:32.641021Z","iopub.execute_input":"2023-07-11T10:52:32.641417Z","iopub.status.idle":"2023-07-11T10:52:32.658223Z","shell.execute_reply.started":"2023-07-11T10:52:32.641385Z","shell.execute_reply":"2023-07-11T10:52:32.657197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n\nclass rerankingEfficientNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n        self.model.classifier.fc = nn.Linear(1280, 1)\n        self.model.train()\n        self.act = nn.Sigmoid()\n        self.crit = nn.MSELoss()\n    \n    def forward(self, labels, merged_imgs):\n        logits = self.model(merged_imgs)\n        output = self.act(logits)\n        loss = self.crit(output, labels.unsqueeze(1))\n        return loss, output\n    \n     ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T10:57:19.073853Z","iopub.execute_input":"2023-07-11T10:57:19.074539Z","iopub.status.idle":"2023-07-11T10:57:19.082402Z","shell.execute_reply.started":"2023-07-11T10:57:19.074501Z","shell.execute_reply":"2023-07-11T10:57:19.081090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import ViTImageProcessor, ViTForImageClassification, ViTModel\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader\nimport torch\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom torchvision import transforms\n\n\ntrain_dataset = huydataset(read_data['train'])\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=train_dataset.collate_fn)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = rerankingEfficientNet().to(device)\noptimizer = torch.optim.AdamW(params  = model.parameters(), lr = 1e-3)\nlosses = []\navg_losses = []\nfor epoch in range(5):\n    train_iters = tqdm(train_loader)\n    avg_loss = 0\n    losse = []\n    avg_losse = []\n    for idx, batch in enumerate(train_iters):\n        for key in ['labels', 'merged_imgs']:\n            batch[key] = batch[key].to(device)\n        loss, output = model(**batch)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        avg_loss = (avg_loss*idx+loss)/(idx+1)\n        train_iters.set_postfix({\"avg_loss\":avg_loss.item(), 'loss':loss.item()})\n        losse.append(loss.item())\n        avg_losse.append(avg_loss.item())\n    losses.append(losse)\n    avg_losses.append(avg_losse)\n    \n    torch.save(model.state_dict(), \"/kaggle/working/model.bin\")\n    from huggingface_hub import HfApi\n    api = HfApi()\n    api.upload_file(\n        path_or_fileobj=\"/kaggle/working/model.bin\",\n        path_in_repo=\"model.bin\",\n        repo_id=\"Huy1432884/rerankingShuffleNet\",\n        repo_type=\"model\",\n        token=\"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\"\n    )\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-11T10:57:19.987876Z","iopub.execute_input":"2023-07-11T10:57:19.991402Z","iopub.status.idle":"2023-07-11T11:00:03.155519Z","shell.execute_reply.started":"2023-07-11T10:57:19.991354Z","shell.execute_reply":"2023-07-11T11:00:03.153969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"avg_loss: 0.1523","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nplt.plot(losses[4])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:26:22.048547Z","iopub.status.idle":"2023-07-08T13:26:22.049096Z","shell.execute_reply.started":"2023-07-08T13:26:22.048841Z","shell.execute_reply":"2023-07-08T13:26:22.048865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(avg_losses[1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:26:22.051401Z","iopub.status.idle":"2023-07-08T13:26:22.052317Z","shell.execute_reply.started":"2023-07-08T13:26:22.052048Z","shell.execute_reply":"2023-07-08T13:26:22.052073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/model.bin\")\nfrom huggingface_hub import HfApi\napi = HfApi()\napi.upload_file(\n    path_or_fileobj=\"/kaggle/working/model.bin\",\n    path_in_repo=\"model.bin\",\n    repo_id=\"Huy1432884/rerankingShuffleNet\",\n    repo_type=\"model\",\n    token=\"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\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:26:22.053946Z","iopub.status.idle":"2023-07-08T13:26:22.054800Z","shell.execute_reply.started":"2023-07-08T13:26:22.054505Z","shell.execute_reply":"2023-07-08T13:26:22.054529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%writefile reranking.py\n\nfrom huggingface_hub import hf_hub_download\nimport torch.nn as nn\nfrom PIL import Image\nfrom torchvision import transforms\nfrom transformers import ViTImageProcessor, ViTForImageClassification, ViTModel\nimport torchvision.transforms as T\nimport torch\n\nclass Initial:\n    def __init__(self):\n        self.process = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        \n        self.model = rerankingShuffleNet()\n        version = None\n        # version = \"8c9e868d2c0287d60b23df6d6f29607625356a7d\"\n        hf_hub_download(repo_id=\"Huy1432884/rerankingShuffleNet\", \n            filename=\"model.bin\", \n            use_auth_token=\"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\", \n            local_dir=\"/kaggle/working/\",\n            revision=version\n        )\n        self.model.load_state_dict(torch.load(\"/kaggle/working/model.bin\", map_location=torch.device('cpu')))\n        self.model.eval()\n        \n        \ndef reranking(image1, image2, initial):\n    def merge_height(image1, image2):\n        new_image = Image.new(\"RGB\", (224, 224), (250, 250, 250))\n        new_image.paste(image1,(0,0))\n        new_image.paste(image2,(112,0))\n        return new_image\n    \n    img1 = transforms.Resize((224, 112))(image1)\n    img2 = transforms.Resize((224, 112))(image2)\n    merged_imgs = merge_height(img1, img2)\n    merged_imgs = initial.process(merged_imgs).unsqueeze(0)\n    output = initial.model(merged_imgs)\n    output = output.squeeze(0).squeeze(0).item()\n    return output\n    \nclass rerankingShuffleNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\n        self.model.fc = nn.Linear(1024, 1)\n        self.model.eval()\n        self.act = nn.Sigmoid()\n        self.crit = nn.MSELoss()\n    \n    def forward(self, merged_imgs):\n        logits = self.model(merged_imgs)\n        output = self.act(logits)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:26:22.056508Z","iopub.status.idle":"2023-07-08T13:26:22.057141Z","shell.execute_reply.started":"2023-07-08T13:26:22.056901Z","shell.execute_reply":"2023-07-08T13:26:22.056925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"initial = Initial()","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:26:22.058793Z","iopub.status.idle":"2023-07-08T13:26:22.059829Z","shell.execute_reply.started":"2023-07-08T13:26:22.059568Z","shell.execute_reply":"2023-07-08T13:26:22.059591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:26:22.063482Z","iopub.status.idle":"2023-07-08T13:26:22.064418Z","shell.execute_reply.started":"2023-07-08T13:26:22.064173Z","shell.execute_reply":"2023-07-08T13:26:22.064197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img1)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:26:22.068000Z","iopub.status.idle":"2023-07-08T13:26:22.068821Z","shell.execute_reply.started":"2023-07-08T13:26:22.068525Z","shell.execute_reply":"2023-07-08T13:26:22.068549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img2)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:26:22.070396Z","iopub.status.idle":"2023-07-08T13:26:22.071172Z","shell.execute_reply.started":"2023-07-08T13:26:22.070923Z","shell.execute_reply":"2023-07-08T13:26:22.070946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor i, sample in enumerate(read_data['train']):\n    label = sample[2]\n    if label != 1:\n        continue\n    image1_dir = sample[0]\n    image2_dir = sample[1]\n    if i == 12:\n        img1 = Image.open(image1_dir)\n        img2 = Image.open(image2_dir)\n    image1 = Image.open(image1_dir)\n    image2 = Image.open(image2_dir)\n    output = reranking(image1, image2, initial)\n    print(label)\n    print(output)\n    print('-'*100)\n    if i > 10:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:26:22.072592Z","iopub.status.idle":"2023-07-08T13:26:22.073356Z","shell.execute_reply.started":"2023-07-08T13:26:22.073106Z","shell.execute_reply":"2023-07-08T13:26:22.073130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, sample in enumerate(read_data['test']):\n    image1_dir = sample[0]\n    image2_dir = sample[1]\n    label = sample[2]\n    image1 = Image.open(image1_dir)\n    image2 = Image.open(image2_dir)\n    output = reranking(image1, image2, initial)\n    print(label)\n    print(output)\n    print('-'*100)\n    if i > 10:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-07-08T13:26:22.074701Z","iopub.status.idle":"2023-07-08T13:26:22.075451Z","shell.execute_reply.started":"2023-07-08T13:26:22.075211Z","shell.execute_reply":"2023-07-08T13:26:22.075234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}