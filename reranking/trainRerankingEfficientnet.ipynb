{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T10:26:04.606024Z","iopub.status.busy":"2023-07-11T10:26:04.605020Z","iopub.status.idle":"2023-07-11T10:36:12.925324Z","shell.execute_reply":"2023-07-11T10:36:12.924383Z","shell.execute_reply.started":"2023-07-11T10:26:04.605986Z"},"trusted":true},"outputs":[],"source":["from sklearn.utils import shuffle\n","from tqdm import tqdm\n","import pandas as pd\n","import os\n","read_data = {}\n","data = pd.read_csv(\"/kaggle/input/add-csv/pairs_for_training.csv\")\n","data = shuffle(data)\n","prefix = \"/kaggle/input/imageretrievaldataset/\"\n","a = [data.loc[i].tolist()[1:5] for i in tqdm(range(len(data)))]\n","b = []\n","k = 0\n","i = 0\n","pbar = tqdm(total=len(data)+1)\n","while i < len(data):\n","    if os.path.exists(prefix+a[i][0]) and os.path.exists(prefix+a[i][1]):\n","        b.append([prefix+a[i][0], prefix+a[i][1], a[i][3], a[i][2]])\n","        k+=1\n","        pbar.update(1)\n","    i += 1\n","pbar.close()\n","print(\"Available: \", k)\n","read_data['train'] = b"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T10:36:12.928263Z","iopub.status.busy":"2023-07-11T10:36:12.927550Z","iopub.status.idle":"2023-07-11T10:43:40.294978Z","shell.execute_reply":"2023-07-11T10:43:40.293937Z","shell.execute_reply.started":"2023-07-11T10:36:12.928227Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv(\"/kaggle/input/imageretrievaldataset/pairs_for_testing.csv\")\n","data = shuffle(data)\n","prefix = \"/kaggle/input/imageretrievaldataset/\"\n","a = [data.loc[i].tolist()[1:6] for i in tqdm(range(len(data)))]\n","b = []\n","k = 0\n","i = 0\n","pbar = tqdm(total=len(data)+1)\n","while i < len(data):\n","    if os.path.exists(prefix+a[i][0]) and os.path.exists(prefix+a[i][1]):\n","        b.append([prefix+a[i][0], prefix+a[i][1], a[i][4], a[i][3]])\n","        k+=1\n","        pbar.update(1)\n","    i += 1\n","pbar.close()\n","print(\"Available: \", k)\n","read_data['test'] = b"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T10:52:32.641417Z","iopub.status.busy":"2023-07-11T10:52:32.641021Z","iopub.status.idle":"2023-07-11T10:52:32.658223Z","shell.execute_reply":"2023-07-11T10:52:32.657197Z","shell.execute_reply.started":"2023-07-11T10:52:32.641385Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class huydataset(Dataset):\n","    def __init__(self, file):\n","        firsts = []\n","        seconds = []\n","        labels = []\n","        for line in file:\n","            path1, path2, label, _ = line\n","            firsts.append(path1)\n","            seconds.append(path2)\n","            labels.append(float(label))\n","        self.data = {\"firsts\":firsts, \"seconds\":seconds, \"labels\":labels}\n","        self.preprocess = transforms.Compose([\n","            transforms.Resize(256),\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","        ])\n","    \n","    def __len__(self):\n","        return len(self.data[\"labels\"])\n","    \n","    def __getitem__(self, idx):\n","        def merge_width(image1, image2):\n","            new_image = Image.new(\"RGB\", (image1.size[0], image1.size[1]+image2.size[1]), (250, 250, 250))\n","            new_image.paste(image1,(0,0))\n","            new_image.paste(image2,(0,image1.size[1]))\n","            return new_image\n","        \n","        def merge_height(image1, image2):\n","            new_image = Image.new(\"RGB\", (256, 256), (250, 250, 250))\n","            new_image.paste(image1,(0,0))\n","            new_image.paste(image2,(128,0))\n","            return new_image\n","        \n","        img1 = Image.open(self.data[\"firsts\"][idx])\n","        img1 = transforms.Resize((256, 128))(img1)\n","        img2 = Image.open(self.data[\"seconds\"][idx])\n","        img2 = transforms.Resize((256, 128))(img2)\n","        merged_imgs = self.preprocess(merge_height(img1, img2)).unsqueeze(0)\n","        return {\"labels\":self.data[\"labels\"][idx], \"merged_imgs\":merged_imgs}\n","        \n","    def collate_fn(self, batch):\n","        def get_data(batch):\n","            data = {i:[] for i in batch[0]}\n","            for i in batch:\n","                for k in i:\n","                    data[k].append(i[k])\n","            return data\n","        \n","        batch = get_data(batch)\n","        batch[\"merged_imgs\"] = torch.cat(batch[\"merged_imgs\"], dim=0)\n","        batch[\"labels\"] = torch.tensor(batch[\"labels\"])\n","        return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T10:57:19.074539Z","iopub.status.busy":"2023-07-11T10:57:19.073853Z","iopub.status.idle":"2023-07-11T10:57:19.082402Z","shell.execute_reply":"2023-07-11T10:57:19.081090Z","shell.execute_reply.started":"2023-07-11T10:57:19.074501Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","\n","class rerankingEfficientNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n","        self.model.classifier.fc = nn.Linear(1280, 1)\n","        self.model.train()\n","        self.act = nn.Sigmoid()\n","        self.crit = nn.MSELoss()\n","    \n","    def forward(self, labels, merged_imgs):\n","        logits = self.model(merged_imgs)\n","        output = self.act(logits)\n","        loss = self.crit(output, labels.unsqueeze(1))\n","        return loss, output\n","    \n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-11T10:57:19.991402Z","iopub.status.busy":"2023-07-11T10:57:19.987876Z","iopub.status.idle":"2023-07-11T11:00:03.155519Z","shell.execute_reply":"2023-07-11T11:00:03.153969Z","shell.execute_reply.started":"2023-07-11T10:57:19.991354Z"},"trusted":true},"outputs":[],"source":["from transformers import ViTImageProcessor, ViTForImageClassification, ViTModel\n","import torchvision.transforms as T\n","from torch.utils.data import DataLoader\n","import torch\n","from tqdm import tqdm\n","from PIL import Image\n","from torchvision import transforms\n","\n","\n","train_dataset = huydataset(read_data['train'])\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=train_dataset.collate_fn)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = rerankingEfficientNet().to(device)\n","optimizer = torch.optim.AdamW(params  = model.parameters(), lr = 1e-3)\n","losses = []\n","avg_losses = []\n","for epoch in range(5):\n","    train_iters = tqdm(train_loader)\n","    avg_loss = 0\n","    losse = []\n","    avg_losse = []\n","    for idx, batch in enumerate(train_iters):\n","        for key in ['labels', 'merged_imgs']:\n","            batch[key] = batch[key].to(device)\n","        loss, output = model(**batch)\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        avg_loss = (avg_loss*idx+loss)/(idx+1)\n","        train_iters.set_postfix({\"avg_loss\":avg_loss.item(), 'loss':loss.item()})\n","        losse.append(loss.item())\n","        avg_losse.append(avg_loss.item())\n","    losses.append(losse)\n","    avg_losses.append(avg_losse)\n","    \n","    torch.save(model.state_dict(), \"/kaggle/working/model.bin\")\n","    from huggingface_hub import HfApi\n","    api = HfApi()\n","    api.upload_file(\n","        path_or_fileobj=\"/kaggle/working/model.bin\",\n","        path_in_repo=\"model.bin\",\n","        repo_id=\"Huy1432884/rerankingShuffleNet\",\n","        repo_type=\"model\",\n","        token=\"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\"\n","    )\n","    \n","    "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
